{"abstract":"The rapid increasing of online information is hard to handle.Summaries such as abstracts help us to reduce this problem. Keywords, whichcan be regarded as very short summaries, may help even more. Filteringdocuments by using keywords may save precious time while searching.However, most of the documents do not include keywords. In this paper wepresent a model that extracts keywords from abstracts and titles. This model hasbeen implemented in a prototype system. We have tested our model on a set ofabstracts of Academic papers containing keywords composed by their authors.Results show that keywords extracted from abstracts and titles may be a primarytool for researchers."}
{"abstract":"Keywords are very important for any academic paper. We propose the Perceptron Training Rule for keyword extraction from titles and abstracts. We present a system for generating keywords which relies on weights of words in a sentence. The system generates keywords from academic research articles by selecting the most relevant keywords. We compare the keywords generated by our system and those generated by cluster analysis to the keywords given by the authors and analyze the results based on full-keyword matches, partial-keyword matches and no-keyword matches."}
{"abstract":"Paper presents a survey of methods and approaches for keyword extraction task. In addition to the systematization of methods, the paper gathers a comprehensive review of existing research. Related work on keyword extraction is elaborated for supervised and unsupervised methods, with special emphasis on graphbased methods as well as Croatian keyword extraction. Selectivity-based keyword extraction method is proposed as a new unsupervised graph-based keyword extraction method which extracts nodes from a complex network as keyword candidates. The paper provides guidelines for future research and development of new graph-based approaches for keyword extraction."}
{"abstract":"Every year thousands of academic studies are published all over the world. When researchers search for a topic, they quickly look at abstracts and keywords. In many academic disciplines, the authors write keywords and abstracts in their publications. On the other hand, there are publications of some disciplines, such as social sciences which do not contain keywords and abstracted information. In addition, there may be no abstract or keyword in some of old publications in all disciplines. Search engines for academic publications usually conduct this search by checking keywords, abstracts and titles. The lack of an abstract and a keyword in the publication makes this situation difficult to provide accurate search results and it prevents the researcher to review the publication quickly. This study proposes a method to generate keywords and an abstract from the text that can be used in academic studies. In the previous studies, k-NN and fuzzy CCG methods have been generally used to solve this problem. Nonetheless, the structures of words have not been examined and semantic analysis has not been used for solving this problem. In this study, the sections of the publication are also divided into parts such as the references, the introduction and the methodology. Each section is graded differently so that the word in each section has a different score. Furthermore, NLP methods were used to analyze texts and phrases, removing prepositions and conjunctions. After these processes, the data was used to generate the keyword using TF–IDF. Text generation for abstract is also performed using the TextRank method with this data. Thus, much more successful, truthful and contextually relevant keywords and abstracts are produced. The proposed method was tested on Sobiad Academic Database, which is employed by 72 universities in Turkey, covering more than 250,000 academic publications. Experimental results were measured with precision and F measure, and the results were found to be promising compared to the previous studies, which focused on keyword derivation and abstract generation."}
{"abstract":"We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model."}
{"abstract":"Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and timeconsuming to maintain. This paper proposes the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific search engines. We describe new research in reinforcement learning, text classification and information extraction that enables efficient spidering, populates topic hierarchies, and identifies informative text segments. Using these techniques, we have built a demonstration system: a search engine for computer science research papers available at www.cora.justresearch.com."}
{"abstract":"Cricket is one the most watched sport now-a-days. Winning in cricket depends on various factors like home ground advantage, performances in the past matches, experience of the players, performance at the specific venue,  performance against the specific team and the current form of the team and the player. In the recent past, a lot of research has been done which measures the player ‘s performance and predicts the winning percentage. This article briefs about the factors that cricket game depends on and discusses various researches which predicted the winning of a team with an advent of statistical modeling in sports. Cricket is one of the most popular team games in the world. With this article, we embark on predicting the outcome of Indian Premier League (IPL) cricket match using a supervised learning approach from a team composition  perspective. Our work suggests that the relative team strength between the competing teams forms a distinctive feature for predicting the winner. Modeling the team strength boils down to modeling individual player‘s batting and bowling performances, forming the basis of our approach. We use statistics and recent performance of a player to model him. Player independent factors have also been considered in order to predict the outcome of a match. Machine learning is used in  predicting the outcome of a cricket match before and during a match. "}
{"abstract":"With the increasing use of research paper search engines, such as CiteSeer, for both literature search and hiring decisions, the accuracy of such systems is of paramount importance. This article employs conditional random fields (CRFs) for the task of extracting various common fields from the headers and citation of research papers. CRFs provide a principled way for incorporating various local features, external lexicon features and globle layout features. The basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration. We make an empirical exploration of several factors, including variations on Gaussian, Laplace and hyperbolic-L1 priors for improved regularization, and several classes of features. Based on CRFs, we further present a novel approach for constraint co-reference information extraction; i.e., improving extraction performance given that we know some citations refer to the same publication. On a standard benchmark dataset, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results. Accuracy compares even more favorably against HMMs. On four co-reference IE datasets, our system significantly improves extraction performance, with an error rate reduction of 6–14%."}
{"abstract":"Text Categorization (TC), also known as Text Classification, is the task of automatically classifying a set of text documents into different categories from a predefined set. If a document belongs to exactly one of the categories, it is a single-label classification task; otherwise, it is a multi-label classification task. TC uses several tools from Information Retrieval (IR) and Machine Learning (ML) and has received much attention in the last years from both researchers in the academia and industry developers. In this paper, we first categorize the documents using KNN based machine learning approach and then return the most relevant documents."}
{"abstract":"Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."}
{"abstract":"In this paper, we consider local mesh refinement algorithms and data structures for finite element methods for linear elliptic partial differential equations in the plane. Quadrilateral and triangular are treated in a unified fashion. Because we restrict the local refinement to be regular, the resulting finite element systems are always sparse, and the refinement algorithms can be implemented effciently, in time proportional to the number of elements."}
{"abstract":"A practical data structure and algorithm was proposed in this paper. It is mainly used in drawing and editing polyline graphics in topographical maps. In this structure, the point sequence of graphic data is stored by the class (structure) arrays with two member variables. During drawing and editing graphics, reference points were setup to facilitate the graphics editing, such as moving points and sides, round angling and salient angling, etc. Using this algorithm, other operations, such as moving, rotating and zooming of whole graphics, can be derived. This method has such characteristics of high efficiency, strict theory support and clear geometric relationship. It must be efficient and flexible for drawing and editing polyline graphics of buildings, residential areas, pipelines, etc. of topographic map."}
{"abstract":"This paper tries to throw light in the usage of data structures in the field of information retrieval.Information retrieval is an area of study which is gaining momentum as the need and urge for sharing andexploring information is growing day by day. Data structures have been the area of research for a longperiod in the arena of computer science. The need to have efficient data structures has become even moreimportant as the data grows in an exponential nature. "}
{"abstract":"This paper involves the concept of stack andqueue used in data structure basically two of the morecommon data objects found in computer algorithmsare stacks and queues. Both of these objects arespecial cases of the more general data object, an ordered list.A stack is a container of objects that are inserted andremoved according to the last-in first-out (LIFO) principle. In the pushdown stacks only two operations are allowed: push the item into the stack, and pop the  item out of the stack. A stack is a limited access data structure - elements can be added and removed from the stack only at the top. push adds an item to the top of the stack, pop removes the item from the top. If we talk about the daily life example like a stack of books; you can remove only the top book, also you can add a new book on the top"}
{"abstract":"In the area of computer science education, Algorithm visualization is the most popular tool used, while teaching data structure to undergraduate students. Using this tool student can easily understand concept of data structure and see visually how various operations performed on these data structure. This paper presents a survey on various visualization tool used in the literature from 2001-2013. Various technologies used to develop it, their benefits in learning data structure, limitations, year of publication and their authors. "}
{"abstract":"In this paper we propose an efficient method to rank the research papers from various fields of research published in various conferences over the years. This ranking method is based on citation network. The importance of a research paper is captured well by the peer vote, which in this case is the research paper being cited in other research papers. Using a modified version of the PageRank algorithm, we rank the research papers, assigning each of them an authoritative score. Using the scores of the research papers calculated by above mentioned method, we formulate scores for conferences and authors and rank them as well. We have introduced a new metric in the algorithm which takes into account the time factor in ranking the research papers to reduce the bias against the recent papers which get less time for being studied and consequently cited by the researchers as compared to the older papers. Often a researcher is more interested in finding the top conferences in a particular year rather than the overall conference ranking. Considering the year of publication of the papers, in addition to the paper scores we also calculated the yearwise score of each conference by slight improvisation of the above mentioned algorithm. "}
{"abstract":"This paper presents the implementation of theprocessor of the Image Processing parallel architecture GFLOPS.This processor is a RISC/VLIW. The network module associated inthe chip is such that it is possible to build a large architecture bythe juxtaposition of as many chips as required. An evaluation of thisarchitecture is presented at the end of this paper through the use ofsimulation results"}
{"abstract":"The low power CMOS implementation is based on a combination of MOS transistors operating in di erent modes: weak and stronginversion. We propose, MOS transistors operating in the lateral bipolar mode.This combination has enabled a VLSI implementation of a simpli ed version of the original CNN model with the main characteristics of low-power consumption, program-mability, and embedded photo sensors to process images directly projected on the chip. For VLSI implementations of CNN's .It is usual to consider simpli ed versions of the ChuaYang model in order to reduce circuit com-plexity.Several applications of CNN's in solving image processing tasks such as noise removal, edge and corner detection, hole lling, connected component detection, etc. To obtain low-power consumption and to directly process the small currents from the sensors we useMOS transistors operating in weak inversion for all the di erential pairs .in such a way that only local matching between transistors belonging to each di erential pair is required. Due to their better matching properties, MOS transistors operated in the lateral bipolar mode are used for the distribution of the values dening the programmable parameters (templates A and B, and the o set I), as well as the values that limit the range of the cell output and input. As in other CNN implementations integrated photo sensors are used to allow a parallel and direct input of the images to be processed by the network. The approach considered in and uses a Darlington phototran-sistor in order to provide the appropriate current levels required by the MOS circuitry operating in strong inver-sion. Software proposed to be used is MATlab and VHDL"}
{"abstract":"High speed machines and mechanisms are often studied from a sequence of images obtained from high speed videography. The use of markers printed or attached on moving parts can greatly assist in tracking the moving parts. We present the design of a marker suitable for planar motion analysis of mechanism. The marker is designed to make the task of image processing computationally less intensive so as to make real time motion analysis practical. Rosenfeld equivalence table algorithm is used to segment the input image. The new geometry of marker facilitates automatic tracking and provides both position and orientation information. Hu invariant moments are used for recognition of the marker shape in the segmented image. Markers are uniquely identified on the basis of a text code that is placed in a designated location with respect to the marker geometry. In this method, the bounding box for the text code is computed. Knowing the orientation of the marker and therefore the text orientation, it is possible to transform the sub-image, containing the text, so that the text is aligned horizontally. This will permit a standard OCR routine to read the text code. The motion of various moving parts in image sequence can be easily inferred once the position and orientation of each of the marker is known."}
{"abstract":"Video object segmentation is an important pre-processing task for many video analysis systems. To achieve the requirement of real-time video analysis, hardware acceleration is required. In this paper, after analyzing existing video object segmentation algorithms, it is found that most of the core operations can be implemented with simple morphology operations. Therefore, with the concepts of morphological image processing element array and stream processing, a reconfigurable morphological image processing accelerator is proposed, where by the proposed instruction set, the operation of each processing element can be controlled, and the interconnection between processing elements can also be reconfigured. Simulation results show that most of the core operations of video object segmentation can be supported by the accelerator by only changing the instructions. A prototype chip is designed to support real-time change-detection-andbackground-registration based video object segmentation algorithm. This chip incorporates eight macro processing elements and can support a processing capacity of 6,200 9-bit morphological operations per second on a SIF image. Furthermore, with the proposed tiling and pipelined-parallel techniques, a realtime watershed transform can be achieved using 32 macro processing elements."}
{"abstract":"Digital Image Processing (DIP) is the process of digital images using various computer algorithms. This digital image processing has been employed in number of areas such as pattern recognition, remote sensing, image-sharpening, colour and video processing and medical. This paper presents a brief overview and literature review of digital image processing techniques such as image pre-processing, image compression, edge detection and segmentation."}
{"abstract":"Texting that is SMS is the important function of any Mobile phone and we know that the mobile phone usage in World is spreading rapidly and has gone through great changes due to new developments and innovations in mobile phone technology. This paper based on creating a smart texting system for mobile user because it convert voice into text. In other words, messages can be voice/speech typed. In this paper we will make use of a dictating-machine prototype for the English language, which recognizes in real time natural-language sentences built.. A speech to text converter is developed to send SMS .It is found that large-vocabulary speech recognition can offer a very competitive alternative to traditional text entry"}
{"abstract":"Cellular telephony has had a significant worldwide rate of acceptance, by year 2010 it is estimated that 3.5B of the 6.s8B people in the planet will have access to a cell phone. Smartphone devices such as iPhone, Blackberry, and those that support the Android operating system are progressively making an impact on society. In addition to their support for voice and text exchange, smartphones are capable of executing sophisticated embedded software applications, as well as provide a simple link to the Internet and its resources"}
{"abstract":"This paper describes an application of Java programming language in the imple-mentation of the algorithm for generating triangulations of a convex polygon and their graphical representation. Particularly, we present the method for creating records in the form of the specific Alpa-Numeric notation. Final result is the Java application which displays a corellation between the AN notation and the graphical representation. Generally speaking, our application is applicable in solving of some algorithms in computer graphics"}
{"abstract":"In this paper, I have done the audit of the Java programming language for the students. I will show four models and completely help to students in study. This paper surveys recent research on programming languages and development various models. Enhancements in wherever handling over late conditions has engaged architects to make structures that assistance message in the classroom. Learning includes two methods which are understanding data and changing that learning. We likewise exhibit a different layered Student Model which underpins versatile coaching by gathering the issue particular information state from understudy arrangements. This Research Work is tied in with getting the hang of programming instead of the capable practice. The circumstances are expected for master programming engineers. This paper is an attempt to contemplate how students take in the Java programming Language and make secure use of using it. An understudy in what way can find the weakness of Java application."}
{"abstract":"Java language is become very popular and research project deal with improvement of the language or its run time behaviour. A Java IDE (Integrated Development Environment) is a application which enables users to more easily write the code and debug Java programs. its also helpful for beginners. In this IDEs provide features like syntax highlighting and auto code completion, which help the user to code more easily. The IDE is a Free and Open Source IDE for software developers. The IDE runs on many platforms including Windows, GNU/Linux and Mac OS X. It is easy to install. You can easily create Java applications for mobile devices using Mobility Pack in JIDE. With the IDE has become one of the most preferred development tools, whether it be designing a Swing UI, an enterprise application or using it as a platform for creating your own IDE"}
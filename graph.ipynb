{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nimport pandas as pd\nimport numpy as np\nimport nltk\npunctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Python program for Dijkstra's single \n# source shortest path algorithm. The program is \n# for adjacency matrix representation of the graph \n\n# Library for INT_MAX \ndi=list()\nimport sys \n\nclass Graph(): \n    def __init__(self, vertices): \n        self.V = vertices \n        self.graph = [[0 for column in range(vertices)] \n                      for row in range(vertices)] \n    def printSolution(self, dist): \n        print (\"Vertex \\tDistance from Source\")\n        for node in range(self.V): \n            print (node, \"\\t\", dist[node]) \n\n\t# A utility function to find the vertex with \n\t# minimum distance value, from the set of vertices \n\t# not yet included in shortest path tree \n    def minDistance(self, dist, sptSet):\n        # Initilaize minimum distance for next node \n        min = sys.maxsize\n        # Search not nearest vertex not in the \n        # shortest path tree \n        f=0\n        for v in range(self.V):\n            \n            if dist[v] < min and sptSet[v] == False: \n                f=1\n                min = dist[v] \n                min_index = v\n        if(f==1):\n            return min_index\n        else:\n            return 0\n    # Funtion that implements Dijkstra's single source \n    # shortest path algorithm for a graph represented \n    # using adjacency matrix representation \n    def dijkstra(self, src): \n        dist = [sys.maxsize] * self.V \n        dist[src] = 0\n        sptSet = [False] * self.V \n        for cout in range(self.V): \n            # Pick the minimum distance vertex from \n            # the set of vertices not yet processed. \n            # u is always equal to src in first iteration \n            u = self.minDistance(dist, sptSet) \n            # Put the minimum distance vertex in the \n            # shotest path tree \n            sptSet[u] = True\n            # Update dist value of the adjacent vertices \n            # of the picked vertex only if the current \n            # distance is greater than new distance and \n            # the vertex in not in the shotest path tree \n            for v in range(self.V): \n                if self.graph[u][v] > 0 and sptSet[v] == False and dist[v] > dist[u] + self.graph[u][v]: \n                    dist[v] = dist[u] + self.graph[u][v]\n                if(dist[v]==9223372036854775807):\n                    dist[v]=0\n        di.append(max(dist))\n        #self.printSolution(dist) \n    \n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def graphbased(input_str):\n    #lower string\n    input_str = input_str.lower()\n    result = re.sub(r\"\\d+\", \"\", input_str)\n    #removing punctuation and stopwords\n    no_punct = \"\"\n    for char in result:\n        if char not in punctuations:\n            no_punct = no_punct + char \n    stop_words = set(stopwords.words('english'))\n    #tokenizatio\n    word_tokens = word_tokenize(no_punct) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = []\n    for w in word_tokens:\n        if w not in stop_words: \n            filtered_sentence.append(w) \n    k=''\n    final=[]\n    for w in filtered_sentence: \n        if w not in k: \n            final.append(w) \n\n    #lematization\n    wnl=WordNetLemmatizer()\n    stemlist=[]\n    for word in final:\n        stemlist.append(wnl.lemmatize(word))\n    finalkey=set(stemlist)\n    finalkey=list(finalkey)\n    #creating graph\n    rows, cols = (len(finalkey), len(finalkey)) \n    arr = [[0 for i in range(cols)] for j in range(rows)]\n    li=[]\n    def fun(i,j):\n        substr=i+\" \"+j\n        c=input_str.count(substr)\n        if(c!=0):\n            li.append(substr)\n        return c\n    l=len(finalkey)\n    for i in range(l):\n        for j in range(l):\n            if i==j:\n                arr[i][j]=0\n            else:\n                c=float(fun(finalkey[i],finalkey[j]))\n                if(c==0):\n                    arr[i][j]=0\n                else:\n                    arr[i][j]=float(1/c)\n    \n    li=set(li)\n    li=list(li)\n    \n    g = Graph(len(arr)) \n    g.graph = arr \n#print(g.graph)\n    for i in range(len(arr)):\n        g.dijkstra(i)\n\n    rel=list()\n    for i in range(len(arr)):\n        if di[i]!=0:\n            rel.append(finalkey[i])\n    return rel",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "input_str='''Text Categorization (TC), also known as Text Classification, is the task of automatically\nclassifying a set of text documents into different categories from a predefined set. If a\ndocument belongs to exactly one of the categories, it is a single-label classification task;\notherwise, it is a multi-label classification task. TC uses several tools from Information\nRetrieval (IR) and Machine Learning (ML) and has received much attention in the last years\nfrom both researchers in the academia and industry developers. In this paper, we first\ncategorize the documents using KNN based machine learning approach and then return the\nmost relevant documents.'''\nprint(graphbased(input_str))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['industry', 'also', 'much', 'knn', 'machine', 'last', 'based', 'classification', 'using', 'tc', 'text', 'exactly', 'relevant', 'learning', 'document', 'predefined', 'several', 'received']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
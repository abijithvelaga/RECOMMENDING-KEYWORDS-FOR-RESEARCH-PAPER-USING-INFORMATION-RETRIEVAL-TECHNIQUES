{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import string\nfrom collections import Counter, defaultdict\nfrom itertools import chain, groupby, product\n\nimport nltk\nfrom enum import Enum\nfrom nltk.tokenize import wordpunct_tokenize",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Metric(Enum):\n    \"\"\"Different metrics that can be used for ranking.\"\"\"\n\n    DEGREE_TO_FREQUENCY_RATIO = 0  # Uses d(w)/f(w) as the metric\n    WORD_DEGREE = 1  # Uses d(w) alone as the metric\n    WORD_FREQUENCY = 2  # Uses f(w) alone as the metric\n\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Rake(object):\n    \"\"\"Rapid Automatic Keyword Extraction Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        stopwords=None,\n        punctuations=None,\n        language=\"english\",\n        ranking_metric=Metric.DEGREE_TO_FREQUENCY_RATIO,\n        max_length=100000,\n        min_length=1,\n    ):\n        \"\"\"Constructor.\n        :param stopwords: List of Words to be ignored for keyword extraction.\n        :param punctuations: Punctuations to be ignored for keyword extraction.\n        :param language: Language to be used for stopwords\n        :param max_length: Maximum limit on the number of words in a phrase\n                           (Inclusive. Defaults to 100000)\n        :param min_length: Minimum limit on the number of words in a phrase\n                           (Inclusive. Defaults to 1)\n        \"\"\"\n        # By default use degree to frequency ratio as the metric.\n        if isinstance(ranking_metric, Metric):\n            self.metric = ranking_metric\n        else:\n            self.metric = Metric.DEGREE_TO_FREQUENCY_RATIO\n\n        # If stopwords not provided we use language stopwords by default.\n        self.stopwords = stopwords\n        if self.stopwords is None:\n            self.stopwords = nltk.corpus.stopwords.words(language)\n\n        # If punctuations are not provided we ignore all punctuation symbols.\n        self.punctuations = punctuations\n        if self.punctuations is None:\n            self.punctuations = string.punctuation\n\n        # All things which act as sentence breaks during keyword extraction.\n        self.to_ignore = set(chain(self.stopwords, self.punctuations))\n\n        # Assign min or max length to the attributes\n        self.min_length = min_length\n        self.max_length = max_length\n\n        # Stuff to be extracted from the provided text.\n        self.frequency_dist = None\n        self.degree = None\n        self.rank_list = None\n        self.ranked_phrases = None\n\n    def extract_keywords_from_text(self, text):\n        \"\"\"Method to extract keywords from the text provided.\n        :param text: Text to extract keywords from, provided as a string.\n        \"\"\"\n        sentences = nltk.tokenize.sent_tokenize(text)\n        self.extract_keywords_from_sentences(sentences)\n\n    def extract_keywords_from_sentences(self, sentences):\n        \"\"\"Method to extract keywords from the list of sentences provided.\n        :param sentences: Text to extraxt keywords from, provided as a list\n                          of strings, where each string is a sentence.\n        \"\"\"\n        phrase_list = self._generate_phrases(sentences)\n        self._build_frequency_dist(phrase_list)\n        self._build_word_co_occurance_graph(phrase_list)\n        self._build_ranklist(phrase_list)\n\n    def get_ranked_phrases(self):\n        \"\"\"Method to fetch ranked keyword strings.\n        :return: List of strings where each string represents an extracted\n                 keyword string.\n        \"\"\"\n        return self.ranked_phrases\n\n    def get_ranked_phrases_with_scores(self):\n        \"\"\"Method to fetch ranked keyword strings along with their scores.\n        :return: List of tuples where each tuple is formed of an extracted\n                 keyword string and its score. Ex: (5.68, 'Four Scoures')\n        \"\"\"\n        return self.rank_list\n\n    def get_word_frequency_distribution(self):\n        \"\"\"Method to fetch the word frequency distribution in the given text.\n        :return: Dictionary (defaultdict) of the format `word -> frequency`.\n        \"\"\"\n        return self.frequency_dist\n\n    def get_word_degrees(self):\n        \"\"\"Method to fetch the degree of words in the given text. Degree can be\n        defined as sum of co-occurances of the word with other words in the\n        given text.\n        :return: Dictionary (defaultdict) of the format `word -> degree`.\n        \"\"\"\n        return self.degree\n\n    def _build_frequency_dist(self, phrase_list):\n        \"\"\"Builds frequency distribution of the words in the given body of text.\n        :param phrase_list: List of List of strings where each sublist is a\n                            collection of words which form a contender phrase.\n        \"\"\"\n        self.frequency_dist = Counter(chain.from_iterable(phrase_list))\n\n    def _build_word_co_occurance_graph(self, phrase_list):\n        \"\"\"Builds the co-occurance graph of words in the given body of text to\n        compute degree of each word.\n        :param phrase_list: List of List of strings where each sublist is a\n                            collection of words which form a contender phrase.\n        \"\"\"\n        co_occurance_graph = defaultdict(lambda: defaultdict(lambda: 0))\n        for phrase in phrase_list:\n            # For each phrase in the phrase list, count co-occurances of the\n            # word with other words in the phrase.\n            #\n            # Note: Keep the co-occurances graph as is, to help facilitate its\n            # use in other creative ways if required later.\n            for (word, coword) in product(phrase, phrase):\n                co_occurance_graph[word][coword] += 1\n        self.degree = defaultdict(lambda: 0)\n        for key in co_occurance_graph:\n            self.degree[key] = sum(co_occurance_graph[key].values())\n\n    def _build_ranklist(self, phrase_list):\n        \"\"\"Method to rank each contender phrase using the formula\n              phrase_score = sum of scores of words in the phrase.\n              word_score = d(w)/f(w) where d is degree and f is frequency.\n        :param phrase_list: List of List of strings where each sublist is a\n                            collection of words which form a contender phrase.\n        \"\"\"\n        self.rank_list = []\n        for phrase in phrase_list:\n            rank = 0.0\n            for word in phrase:\n                if self.metric == Metric.DEGREE_TO_FREQUENCY_RATIO:\n                    rank += 1.0 * self.degree[word] / self.frequency_dist[word]\n                elif self.metric == Metric.WORD_DEGREE:\n                    rank += 1.0 * self.degree[word]\n                else:\n                    rank += 1.0 * self.frequency_dist[word]\n            self.rank_list.append((rank, \" \".join(phrase)))\n        self.rank_list.sort(reverse=True)\n        self.ranked_phrases = [ph[1] for ph in self.rank_list]\n\n    def _generate_phrases(self, sentences):\n        \"\"\"Method to generate contender phrases given the sentences of the text\n        document.\n        :param sentences: List of strings where each string represents a\n                          sentence which forms the text.\n        :return: Set of string tuples where each tuple is a collection\n                 of words forming a contender phrase.\n        \"\"\"\n        phrase_list = set()\n        # Create contender phrases from sentences.\n        for sentence in sentences:\n            word_list = [word.lower() for word in wordpunct_tokenize(sentence)]\n            phrase_list.update(self._get_phrase_list_from_words(word_list))\n        return phrase_list\n\n    def _get_phrase_list_from_words(self, word_list):\n        \"\"\"Method to create contender phrases from the list of words that form\n        a sentence by dropping stopwords and punctuations and grouping the left\n        words into phrases. Only phrases in the given length range (both limits\n        inclusive) would be considered to build co-occurrence matrix. Ex:\n        Sentence: Red apples, are good in flavour.\n        List of words: ['red', 'apples', \",\", 'are', 'good', 'in', 'flavour']\n        List after dropping punctuations and stopwords.\n        List of words: ['red', 'apples', *, *, good, *, 'flavour']\n        List of phrases: [('red', 'apples'), ('good',), ('flavour',)]\n        List of phrases with a correct length:\n        For the range [1, 2]: [('red', 'apples'), ('good',), ('flavour',)]\n        For the range [1, 1]: [('good',), ('flavour',)]\n        For the range [2, 2]: [('red', 'apples')]\n        :param word_list: List of words which form a sentence when joined in\n                          the same order.\n        :return: List of contender phrases that are formed after dropping\n                 stopwords and punctuations.\n        \"\"\"\n        groups = groupby(word_list, lambda x: x not in self.to_ignore)\n        phrases = [tuple(group[1]) for group in groups if group[0]]\n        return list(\n            filter(\n                lambda x: self.min_length <= len(x) <= self.max_length, phrases\n            )\n        )",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}